import datetime
import io
import json
import os
import tempfile
import time
from pathlib import Path
from typing import Any, Dict, List

import faiss
import openai
import python_minifier
import requests
import streamlit as st
from langchain import PromptTemplate
from langchain.agents import AgentType, initialize_agent, load_tools
from langchain.callbacks.base import BaseCallbackManager
from langchain.callbacks.streamlit import StreamlitCallbackHandler
from langchain.chains import QAGenerationChain
from langchain.chains.summarize import load_summarize_chain
from langchain.chat_models import ChatOpenAI
from langchain.docstore.document import Document
from langchain.prompts import (
    ChatPromptTemplate,
    HumanMessagePromptTemplate,
    SystemMessagePromptTemplate,
)
from langchain.prompts.chat import (
    ChatPromptTemplate,
    HumanMessagePromptTemplate,
    SystemMessagePromptTemplate,
)
from langchain.text_splitter import RecursiveCharacterTextSplitter
from llama_index import (
    GPTVectorStoreIndex,
    PromptHelper,
    ServiceContext,
    StorageContext,
    download_loader,
    load_index_from_storage,
)
from llama_index.llm_predictor.chatgpt import ChatGPTLLMPredictor
from llama_index.vector_stores.faiss import FaissVectorStore
from streamlit_lottie import st_lottie, st_lottie_spinner


# prompts„ÅÆÂá∫Âäõ„ÇíË°å„Çè„Å™„ÅÑ„Åü„ÇÅ„É©„ÉÉ„Éó
class WrapStreamlitCallbackHandler(StreamlitCallbackHandler):
    def on_llm_start(
        self, serialized: Dict[str, Any], prompts: List[str], **kwargs: Any
    ) -> None:
        pass


def chunk_splitter(text):
    # „ÉÅ„É£„É≥„ÇØ„Å´ÂàÜÂâ≤
    text_splitter = RecursiveCharacterTextSplitter(
        separators=["\n\n", "\n", "„ÄÇ", "„ÄÅ", " ", ""],
        chunk_size=500,  # „ÉÅ„É£„É≥„ÇØ„ÅÆÊúÄÂ§ß„Éà„Éº„ÇØ„É≥Êï∞
        chunk_overlap=20,  # „ÉÅ„É£„É≥„ÇØ„Ç™„Éº„Éê„Éº„É©„ÉÉ„Éó„ÅÆ„Éà„Éº„ÇØ„É≥Êï∞
    )
    texts = text_splitter.split_text(text)
    return texts


def load_lottieurl(url: str):
    r = requests.get(url)
    if r.status_code != 200:
        return None
    return r.json()


def make_query_engine(data, llm, reading, name):

    check_name = name.lower()
    if reading:
        # „Ç§„É≥„Éá„ÉÉ„ÇØ„Çπ„ÅÆË™≠„ÅøËæº„Åø
        storage_context = StorageContext.from_defaults(persist_dir="./storage")
        index = load_index_from_storage(storage_context)
    else:
        prompt_helper = PromptHelper(
            max_input_size=4096, num_output=2048, max_chunk_overlap=20
        )
        llm_predictor = ChatGPTLLMPredictor(llm=llm)
        service_context = ServiceContext.from_defaults(
            llm_predictor=llm_predictor,
            prompt_helper=prompt_helper,
            chunk_size_limit=512,
        )
        if ".pdf" in check_name:
            PDFReader = download_loader("PDFReader")
            loader = PDFReader()
            documents = loader.load_data(file=data)
        elif any([".txt" in check_name, ".md" in name]):
            MarkdownReader = download_loader("MarkdownReader")
            loader = MarkdownReader()
            documents = loader.load_data(file=data)
        elif ".pptx" in check_name:
            PptxReader = download_loader("PptxReader")
            loader = PptxReader()
            documents = loader.load_data(file=data)
        elif ".docx" in check_name:
            DocxReader = download_loader("DocxReader")
            loader = DocxReader()
            documents = loader.load_data(file=data)
        elif any([".mp3" in check_name, ".mp4" in check_name]):
            AudioTranscriber = download_loader("AudioTranscriber")
            loader = AudioTranscriber()
            documents = loader.load_data(file=data)
        elif ".csv" in check_name:
            PandasCSVReader = download_loader("PandasCSVReader")
            loader = PandasCSVReader()
            documents = loader.load_data(file=data)
        elif "youtu" in check_name:
            YoutubeTranscriptReader = download_loader("YoutubeTranscriptReader")
            loader = YoutubeTranscriptReader()
            documents = loader.load_data(ytlinks=[name])
        elif "http" in check_name:
            BeautifulSoupWebReader = download_loader("BeautifulSoupWebReader")
            loader = BeautifulSoupWebReader()
            documents = loader.load_data(urls=[name])
        # elif ext in [".png", ".jpeg", ".jpg"]:
        #     ImageCaptionReader = download_loader("ImageCaptionReader")
        #     loader = ImageCaptionReader()
        #     documents = loader.load_data(file=data)
        else:
            try:
                MarkdownReader = download_loader("MarkdownReader")
                loader = MarkdownReader()
                documents = loader.load_data(file=data)
            except:
                st.error(f"ÈùûÂØæÂøú„ÅÆ„Éï„Ç°„Ç§„É´ÂΩ¢Âºè„Åß„Åô„ÄÇÔºö{name}")
                st.stop()

        # dimensions of text-ada-embedding-002
        d = 1536
        # „Ç≥„Çµ„Ç§„É≥È°û‰ººÂ∫¶
        faiss_index = faiss.IndexFlatIP(d)
        vector_store = FaissVectorStore(faiss_index=faiss_index)
        storage_context = StorageContext.from_defaults(vector_store=vector_store)

        index = GPTVectorStoreIndex.from_documents(
            documents, faiss_index=faiss_index, service_context=service_context
        )
        # „Ç§„É≥„Éá„ÉÉ„ÇØ„Çπ„ÅÆ‰øùÂ≠ò
        # index.storage_context.persist()

    query_engine = index.as_query_engine(
        similarity_top_k=3,
    )

    return query_engine, documents


def chat(text, settings, model):
    # # ‰ΩøÁî®„Åô„Çã„ÉÑ„Éº„É´„Çí„É≠„Éº„Éâ
    # tools = ["google-search", "python_repl"]
    # tools = load_tools(tools, llm=model)

    # system_template = settings
    # human_template = "Ë≥™ÂïèËÄÖÔºö{question}"
    # system_message_prompt = SystemMessagePromptTemplate.from_template(system_template)
    # human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)

    # chat_prompt = ChatPromptTemplate.from_messages(
    #     [system_message_prompt, human_message_prompt]
    # )
    # prompt_message_list = chat_prompt.format_prompt(
    #     language="Êó•Êú¨Ë™û", question=text
    # ).to_messages()
    # print(prompt_message_list)
    # try:
    #     agent = initialize_agent(
    #         tools=tools,
    #         llm=model,
    #         agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,
    #         verbose=True,
    #     )
    #     response = agent.run(prompt_message_list)

    # except Exception as e:
    #     response = str(e)
    #     if not response.startswith("Could not parse LLM output: `"):
    #         raise e
    #     response = response.removeprefix("Could not parse LLM output: `").removesuffix(
    #         "`"
    #     )

    # return response
    messages = [
        {"role": "system", "content": settings},
        {"role": "user", "content": text},
    ]

    try_count = 3
    error_mes = ""
    for try_time in range(try_count):
        try:
            resp = openai.ChatCompletion.create(
                model=model,
                messages=messages,
                stream=True,
                timeout=120,
                request_timeout=120,
            )
            return resp

        except openai.error.APIError as e:
            print(e)
            print(f"retry:{try_time+1}/{try_count}")
            error_mes = e
            time.sleep(1)
        except openai.error.InvalidRequestError as e:
            print(e)
            print(f"retry:{try_time+1}/{try_count}")
            error_mes = e
            pass
        except (
            openai.error.RateLimitError,
            openai.error.openai.error.APIConnectionError,
        ) as e:
            print(e)
            print(f"retry:{try_time+1}/{try_count}")
            error_mes = e
            time.sleep(10)

    st.error(error_mes)
    st.stop()


def disable():
    st.session_state.disabled = True


def create_messages(
    input_gen_length,
    inputtext,
    supplement,
    select_preset,
    orginal_file,
    preset_file,
):
    if select_preset == "Ë≥™Âïè":
        instructions = f"""
„É´„Éº„É´:Markdown„ÅßÂá∫Âäõ„ÄÇÊó•Êú¨Ë™û„ÅßÂá∫Âäõ„ÄÇ„Éá„Éº„Çø„ÅÆÂèØË¶ñÂåñ„Å´„ÅØplotly„ÇíÁî®„ÅÑ„Çã„ÄÇUML„ÇíË°®Áèæ„Åô„ÇãÈöõ„ÅØmermaid.jsÂΩ¢Âºè„ÅßÂá∫Âäõ„Åô„Çã„ÄÇ {supplement} \n{preset_file["action"][select_preset]["prompt"]}
"""
    else:
        prompt = (
            preset_file["action"][select_preset]["prompt"]
            if orginal_file
            else preset_file["genre"][select_preset]["prompt"]
        )
        instructions = f"""
„ÅÇ„Å™„Åü„ÅØ{inputtext}„ÅÆÂ∞ÇÈñÄÂÆ∂„Åß„Åô„ÄÇ
‰ΩúÊàê„Å´ÂΩì„Åü„Å£„Å¶„ÅØ‰ª•‰∏ã„Å´Âé≥ÂØÜ„Å´Âæì„Å£„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ
- ÂõûÁ≠î„ÅØÊó•Êú¨Ë™û„ÅßË°å„ÅÜ„ÄÇ
- ÊñáÂ≠óÊï∞„ÅØ{input_gen_length}„Å®„Åô„Çã„ÄÇ
- ÊåáÁ§∫„ÅÆÊúÄÂæå„Å´Á∂ö„Åç„ÇíÂá∫Âäõ„Å®ÈÄÅ„Çâ„Çå„ÅüÂ†¥Âêà„ÅØ„ÄÅÁ∂ö„Åç„ÇíÂá∫Âäõ„ÅÆÂâç„ÅÆÊñáÁ´†„ÅÆÁ∂ö„Åç„ÇíÂá∫Âäõ„Åô„Çã„ÄÇ
- step by step„ÅßË§áÊï∞ÂõûÊ§úË®é„ÇíË°å„ÅÑ„ÄÅ„Åù„ÅÆ‰∏≠„Åß‰∏ÄÁï™ÂÑ™„Çå„Å¶„ÅÑ„Çã„Å®ÊÄù„ÅÜÁµêÊûú„ÇíÂá∫Âäõ„Åô„Çã„ÄÇ
- Âá∫Âäõ„ÅØMarkdown„Å®„Åô„Çã„ÄÇ
- UML„ÇíË°®Áèæ„Åô„ÇãÈöõ„ÅØmermaid.jsÂΩ¢Âºè„ÅßÂá∫Âäõ„Åô„Çã„ÄÇ
- „Éá„Éº„Çø„ÅÆÂèØË¶ñÂåñ„Å´„ÅØplotly„ÇíÁî®„ÅÑ„Çã„ÄÇ
- ÁîüÊàêÁâ©‰ª•Â§ñ„ÅØÂá∫Âäõ„Åó„Å™„ÅÑÔºà‰æã„Åà„Å∞ÁîüÊàêÁâ©„Å´ÂØæ„Åô„Çã„Ç≥„É°„É≥„Éà„ÇÑË™¨Êòé„Å™„Å©Ôºâ
{supplement}
{prompt}
            """
    return instructions


def main():
    if "alltext" not in st.session_state:
        st.session_state.alltext = []
        st.session_state.savetext = []
        st.session_state.disabled = False

    input_gen_length = 0
    inputtext = ""
    supplement = ""
    select_preset = ""
    orginal_file = None
    preset_file = None

    # Áã¨Ëá™„Éá„Éº„Çø„ÅÆ„ÅÜ„Å°„ÄÅ„Éó„É≠„Ç∞„É©„É†„Ç≥„Éº„Éâ„ÇíË™≠„ÅøËæº„ÇÄ„ÇÇ„ÅÆ
    cord_reading = ["„Ç≥„Éº„ÉâË™¨Êòé", "„Ç≥„Éº„Éâ„É¨„Éì„É•„Éº„Éª„É™„Éï„Ç°„ÇØ„Çø„É™„É≥„Ç∞", "„ÉÜ„Çπ„ÉàÁîüÊàê"]

    with open("preset.json", encoding="utf-8") as f1:
        preset_file = json.loads(f1.read())

    all_genre = "\n".join(
        [
            f"| {key} | {value['description']}|"
            for key, value in preset_file["genre"].items()
        ]
    )
    all_action = "\n".join(
        [
            f"| {key} | {value['description']}|"
            for key, value in preset_file["action"].items()
        ]
    )

    col1, col2, _ = st.columns(3)
    with col2:
        st.markdown("#")
        st.markdown("# LearnMate.AI ")
    with col1:
        lottie_url = "https://assets9.lottiefiles.com/packages/lf20_glpbhbuh.json"
        lottie_json = load_lottieurl(lottie_url)
        st_lottie(lottie_json, height=150, loop=False)

    message_place = st.empty()

    with st.sidebar:
        model = st.selectbox("„É¢„Éá„É´„ÇíÈÅ∏Êäû", ["gpt-3.5-turbo", "gpt-4"])
        tab1, tab2 = st.tabs(["„Éâ„Ç≠„É•„É°„É≥„ÉàÁîüÊàê", "Áã¨Ëá™„Éá„Éº„Çø"])
        with tab1:
            with st.form("tab1"):
                inputtext = st.text_input("„ÉÜ„Éº„Éû", help="ÁîüÊàê„Åó„Åü„ÅÑ„Éâ„Ç≠„É•„É°„É≥„Éà„ÅÆ„ÉÜ„Éº„Éû„ÇíË®òÂÖ•„ÄÇÂøÖÈ†àÈ†ÖÁõÆ„ÄÇ")
                supplement1 = st.text_area(
                    "ÂÖ•Âäõ", help="Âèñ„ÇäËæº„Çì„ÅßÊ¨≤„Åó„ÅÑÂÜÖÂÆπ„ÄÅÂèñ„ÇäËæº„Çì„ÅßÊ¨≤„Åó„Åè„Å™„ÅÑÂÜÖÂÆπ„ÄÅ„Åù„ÅÆ‰ªñÊåáÁ§∫„ÇíË®òÂÖ•"
                )
                select_preset1 = st.selectbox("„Ç∏„É£„É≥„É´", preset_file["genre"].keys())
                input_gen_length = st.number_input(
                    "ÁîüÊàêÊñáÂ≠óÊï∞„ÇíÂÖ•Âäõ",
                    min_value=0,
                    step=100,
                    value=3000,
                    help="0„Å´Ë®≠ÂÆö„Åô„Çã„Å®ÊåáÂÆö„Å™„Åó„Å®„Å™„Çä„Åæ„Åô„ÄÇ",
                )

                reading = True

                submit1 = st.form_submit_button(
                    "ÁîüÊàêÈñãÂßã",  # on_click=disable, disabled=st.session_state.disabled
                )

        with tab2:
            with st.form("tab2"):
                select_preset2 = st.selectbox("„Ç¢„ÇØ„Ç∑„Éß„É≥", preset_file["action"].keys())
                supplement2 = st.text_area("ÂÖ•Âäõ", help="‰ªªÊÑè")
                select_file = st.file_uploader("„Éï„Ç°„Ç§„É´")
                youtube_url = st.text_input(
                    "URL (WebSite,Youtube...)", help="Youtube„ÅØÂ≠óÂπï‰ªòÂãïÁîª„ÅÆ„Åø„ÄÇ"
                )

                orginal_file = select_file if select_file else youtube_url

                reading = True

                submit2 = st.form_submit_button(
                    "ÁîüÊàêÈñãÂßã",  # on_click=disable, disabled=st.session_state.disabled
                )

    with st.expander("üìöLearnMate.AI„Å®„ÅØ"):
        st.markdown(
            f"""
#### „ÉªÊåáÂÆö„Åï„Çå„Åü„ÉÜ„Éº„Éû„Å´„Å§„ÅÑ„Å¶„ÄÅÈÅ∏Êäû„Åó„ÅüÂΩ¢Âºè„ÅÆË≥áÊñô„ÇíÁîüÊàê„Åô„ÇãAI„Åß„Åô„ÄÇ  

1. „Éâ„Ç≠„É•„É°„É≥„ÉàÁîüÊàê :ÁâπÂÆö„ÅÆ„ÉÜ„Éº„Éû„Å´„Å§„ÅÑ„Å¶„Åæ„Å®„ÇÅ„ÅüË≥áÊñô„ÇíÁîüÊàê„Åô„Çã
2. Áã¨Ëá™„Éá„Éº„Çø :Áã¨Ëá™„ÅÆ„Éá„Éº„Çø„Å´ÂØæ„Åó„Å¶Ë≥™Âïè„ÄÅË¶ÅÁ¥Ñ„ÄÅ„É¨„Éì„É•„Éº„ÄÅ„É™„Éï„Ç°„ÇØ„Çø„É™„É≥„Ç∞„Å™„Å©„ÇíË°å„ÅÜ

#### „Éª„Éâ„Ç≠„É•„É°„É≥„ÉàÁîüÊàê„Ç∏„É£„É≥„É´‰∏ÄË¶ß

|„Ç∏„É£„É≥„É´|Ë™¨Êòé|
|---|---|
{all_genre}

#### „ÉªÁã¨Ëá™„Éá„Éº„Çø„Å´ÂØæ„Åô„Çã„Ç¢„ÇØ„Ç∑„Éß„É≥‰∏ÄË¶ß

|„Ç¢„ÇØ„Ç∑„Éß„É≥|Ë™¨Êòé|
|---|---|
{all_action}

> Ê¥ªÁî®‰æã
> - ÁâπÂÆö„ÅÆ„ÉÜ„Éº„Éû„Å´Ê≤ø„Å£„ÅüÁ†î‰øÆË≥áÊñô‰ΩúÊàê
> - Ëá™Â∑±Â≠¶ÁøíÁî®„ÅÆË≥áÊñô‰ΩúÊàê
> - Á§æÂÜÖË≥áÊñô„Çí„ÇÇ„Å®„Å´Êñ∞Ë¶èÂèÇÂÖ•ËÄÖ„ÅÆÂèóÂÖ•Ë≥áÊñô‰ΩúÊàê„ÄÅ„Éû„Éã„É•„Ç¢„É´„ÅÆ‰ΩúÊàê  
> - ‰ºöË≠∞„ÅÆÈå≤Èü≥„Éá„Éº„Çø„ÇíÂÖÉ„Å´Ë≠∞‰∫ãÈå≤„Çí‰ΩúÊàê  
> - „Ç¶„Çß„Éñ„Éö„Éº„Ç∏„ÅÆË¶ÅÁ¥Ñ  
> - YoutubeÂãïÁîª„ÅÆË¶ÅÁ¥ÑÔºàÂ≠óÂπï‰ªò„ÅçÂãïÁîª„ÅÆ„ÅøÔºâ
"""
        )
        st.caption("*powered by GPT-3,GPT-4*")

    for no, info in enumerate(st.session_state.savetext):
        t_delta = datetime.timedelta(hours=9)
        JST = datetime.timezone(t_delta, "JST")
        now = datetime.datetime.now(JST)
        with st.expander(f'{info["theme"]} : {info["origine_name"]}'):
            if info["origine_name"]:
                data = f"## {info['theme']} : {info['origine_name']}\nÂÖ•Âäõ : {info['supplement']}\n---\n{info['value']}"
            else:
                data = info["theme"] + "\n" + info["value"]
            marp = """
---
marp: true
theme: normal
paginate: true
class: invert
---
<!--
headingDivider: 2
-->

            """
            st.download_button(
                "„ÉÜ„Ç≠„Çπ„Éà„Çí„ÉÄ„Ç¶„É≥„É≠„Éº„Éâ",
                file_name=f"{info['theme']}_{now.strftime('%Y%m%d%H%M%S')}.md",
                data=marp + data if select_preset == "„Éó„É¨„Çº„É≥„ÉÜ„Éº„Ç∑„Éß„É≥„Çπ„É©„Ç§„Éâ‰ΩúÊàê" else data,
                mime="text/plain",
                key=f"old_text{no}",
            )
            if info["origine_name"]:
                st.markdown(f"## {info['theme']} : {info['origine_name']}")
                st.markdown(f"ÂÖ•Âäõ : {info['supplement']}")
                st.markdown("---")
                st.markdown(f"{info['value']}")

            else:
                st.markdown(f"## {info['theme']}")
                st.markdown(info["value"])

    if any([submit1, submit2]):
        st.session_state.alltext = []
        if submit1:
            supplement = supplement1
            select_preset = select_preset1
            orginal_file = ""
            if not inputtext:
                message_place.error("„ÉÜ„Éº„Éû„ÇíÂÖ•Âäõ„Åó„Å¶„Åè„Å†„Åï„ÅÑ", icon="ü•∫")
                st.stop()

        if submit2:
            supplement = supplement2
            select_preset = select_preset2
            inputtext = select_preset2

        instructions = create_messages(
            input_gen_length,
            inputtext,
            supplement,
            select_preset,
            orginal_file,
            preset_file,
        )

        st.markdown("---")
        if orginal_file:
            if type(orginal_file) == str:
                st.markdown(f"## {inputtext} : {orginal_file}")
            else:
                st.markdown(f"## {inputtext} : {orginal_file.name}")
        else:
            st.markdown(f"## {inputtext}")

        status_place = st.container()
        lottie_url = "https://assets4.lottiefiles.com/packages/lf20_45movo.json"
        spinner_lottie_json = load_lottieurl(lottie_url)
        with st_lottie_spinner(spinner_lottie_json, height=200):
            st.markdown("---")
            llm = ChatOpenAI(
                temperature=0,
                model_name=model,
                streaming=True,
                max_tokens=2000,
                callback_manager=BaseCallbackManager(
                    [WrapStreamlitCallbackHandler()],
                ),
            )

            if all(
                [
                    orginal_file,
                    select_preset not in cord_reading,
                ]
            ):
                if type(orginal_file) == str:
                    query_engine, documents = make_query_engine(
                        orginal_file,
                        llm=llm,
                        reading=False,
                        name=orginal_file,
                    )
                    file_text = documents[0].text
                else:
                    with tempfile.NamedTemporaryFile(delete=False) as tmp_file:
                        fp = Path(tmp_file.name)
                        fp.write_bytes(orginal_file.getvalue())
                        query_engine, documents = make_query_engine(
                            fp,
                            llm=llm,
                            reading=False,
                            name=orginal_file.name,
                        )
                        file_text = documents[0].text
            if select_preset in cord_reading:
                file_text = (
                    preset_file["action"][select_preset]["prompt"]
                    + "\n------------\n"
                    + python_minifier.minify(
                        io.StringIO(orginal_file.getvalue().decode("utf-8")).read()
                    )
                )

            text = ""

            if all(
                [
                    orginal_file,
                    select_preset == "Q&AÁîüÊàê",
                ]
            ):
                # QA„ÅÆÁîüÊàê
                templ1 = """You are a smart assistant designed to help high school teachers come up with reading comprehension questions.
                Given a piece of text, you must come up with a question and answer pair that can be used to test a student's reading comprehension abilities.
                When coming up with this question/answer pair, you must respond in the following format:
                ```
                {{
                    "question": "$YOUR_QUESTION_HERE",
                    "answer": "$THE_ANSWER_HERE"
                }}
                ```

                Everything between the ``` must be valid json.
                answer in Japanese.
                """
                templ2 = """Please come up with a question/answer pair, in the specified JSON format, for the following text:
                ----------------
                {text}"""

                # „Éó„É≠„É≥„Éó„Éà„ÉÜ„É≥„Éó„É¨„Éº„Éà„ÅÆÊ∫ñÂÇô
                prompt = ChatPromptTemplate.from_messages(
                    [
                        SystemMessagePromptTemplate.from_template(templ1),
                        HumanMessagePromptTemplate.from_template(templ2),
                    ]
                )
                texts = chunk_splitter(file_text)
                chain = QAGenerationChain.from_llm(llm=llm, prompt=prompt)
                for value in texts:
                    st.write(chain.run(value))
                text = "\n".join(texts)

            elif all(
                [
                    orginal_file,
                    select_preset == "Ë≥™Âïè",
                ]
            ):
                response = query_engine.query(instructions)

            elif all(
                [
                    orginal_file,
                    select_preset == "Ë¶ÅÁ¥Ñ",
                ]
            ):
                prompt_template = f"""Write a concise summary of the following:


{{text}}

{supplement}
CONCISE SUMMARY IN JAPANESE:"""
                PROMPT = PromptTemplate(
                    template=prompt_template, input_variables=["text"]
                )
                texts = chunk_splitter(file_text)
                chain = load_summarize_chain(llm, chain_type="stuff", prompt=PROMPT)
                docs = [Document(page_content=t) for t in texts[:3]]
                text = chain.run(docs)

            else:
                prompt = inputtext + file_text if orginal_file else inputtext
                st.session_state.alltext.append(prompt)
                finish_reason = "init"
                new_place = st.empty()

                while True:
                    if finish_reason == "init":
                        message = "".join(st.session_state.alltext)
                    elif finish_reason == "stop":
                        break
                    elif finish_reason == "length":
                        message = "".join(st.session_state.alltext) + "Á∂ö„Åç„ÇíÂá∫Âäõ"
                    else:
                        st.error(f"„Ç®„É©„Éº„ÅåÁô∫Áîü„Åó„Åæ„Åó„Åü„ÄÇfinish_reason={finish_reason}")
                        st.stop

                    if model == "gpt-3.5-turbo":
                        message = message[-2500:]
                    else:
                        message = message[-6500:]

                    completion = chat(
                        text=message,
                        settings=instructions,
                        model=model,
                    )
                    for chunk in completion:
                        finish_reason = chunk["choices"][0].get("finish_reason", "")
                        next = chunk["choices"][0]["delta"].get("content", "")
                        text += next
                        text = text.replace("Á∂ö„Åç„ÇíÂá∫Âäõ", "")
                        new_place.write(text)

                    st.session_state.alltext.append(text)

            if orginal_file:
                if type(orginal_file) == str:
                    origine_name = orginal_file
                else:
                    origine_name = orginal_file.name
            else:
                origine_name = select_preset

            st.session_state.savetext.append(
                {
                    "theme": inputtext,
                    "value": text if text else response.response,
                    "supplement": supplement,
                    "origine_name": origine_name,
                }
            )

            t_delta = datetime.timedelta(hours=9)
            JST = datetime.timezone(t_delta, "JST")
            now = datetime.datetime.now(JST)

            with status_place:
                lottie_url = "https://assets2.lottiefiles.com/datafiles/8UjWgBkqvEF5jNoFcXV4sdJ6PXpS6DwF7cK4tzpi/Check Mark Success/Check Mark Success Data.json"
                lottie_json = load_lottieurl(lottie_url)
                st_lottie(lottie_json, height=100, loop=False)
                st.download_button(
                    "„ÉÜ„Ç≠„Çπ„Éà„Çí„ÉÄ„Ç¶„É≥„É≠„Éº„Éâ",
                    file_name=f"{inputtext}_{now.strftime('%Y%m%d%H%M%S')}.md",
                    data=text if text else response.response,
                    mime="text/plain",
                    key="current_text",
                )


if __name__ == "__main__":
    st.set_page_config(page_title="LearnMate.AI", page_icon="üìö", layout="wide")

    hide_streamlit_style = """
                <style>
               .block-container {
                    padding-top: 2rem;
                }
                #MainMenu {visibility: hidden;}
                footer {visibility: hidden;}
                </style>
                """
    st.markdown(hide_streamlit_style, unsafe_allow_html=True)

    os.environ["OPENAI_API_KEY"] = st.secrets["OPEN_AI_KEY"]
    # os.environ["GOOGLE_API_KEY"] = st.secrets["GOOGLE_API_KEY"]
    # os.environ["GOOGLE_CSE_ID"] = st.secrets["GOOGLE_CSE_ID"]

    main()
