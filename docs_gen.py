import datetime
import os
import tempfile
import time
from pathlib import Path
from typing import Any, Dict, List

import faiss
import openai
import streamlit as st
from langchain.callbacks.base import BaseCallbackManager
from langchain.callbacks.streamlit import StreamlitCallbackHandler
from langchain.chat_models import ChatOpenAI
from llama_index import (
    GPTVectorStoreIndex,
    PromptHelper,
    ServiceContext,
    StorageContext,
    download_loader,
    load_index_from_storage,
)
from llama_index.llm_predictor.chatgpt import ChatGPTLLMPredictor
from llama_index.vector_stores.faiss import FaissVectorStore


# promptsã®å‡ºåŠ›ã‚’è¡Œã‚ãªã„ãŸã‚ãƒ©ãƒƒãƒ—
class WrapStreamlitCallbackHandler(StreamlitCallbackHandler):
    def on_llm_start(
        self, serialized: Dict[str, Any], prompts: List[str], **kwargs: Any
    ) -> None:
        pass


def make_query_engine(data, llm, reading, name):
    if reading:
        # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®èª­ã¿è¾¼ã¿
        storage_context = StorageContext.from_defaults(persist_dir="./storage")
        index = load_index_from_storage(storage_context)
    else:
        prompt_helper = PromptHelper(
            max_input_size=4096, num_output=2048, max_chunk_overlap=20
        )
        llm_predictor = ChatGPTLLMPredictor(llm=llm)
        service_context = ServiceContext.from_defaults(
            llm_predictor=llm_predictor,
            prompt_helper=prompt_helper,
            chunk_size_limit=512,
        )
        if ".pdf" in name:
            PDFReader = download_loader("PDFReader")
            loader = PDFReader()
            documents = loader.load_data(file=data)
        elif any([".txt" in name, ".md" in name]):
            MarkdownReader = download_loader("MarkdownReader")
            loader = MarkdownReader()
            documents = loader.load_data(file=data)
        elif ".pptx" in name:
            PptxReader = download_loader("PptxReader")
            loader = PptxReader()
            documents = loader.load_data(file=data)
        elif ".docx" in name:
            DocxReader = download_loader("DocxReader")
            loader = DocxReader()
            documents = loader.load_data(file=data)
        elif any([".mp3" in name, ".mp4" in name]):
            AudioTranscriber = download_loader("AudioTranscriber")
            loader = AudioTranscriber()
            documents = loader.load_data(file=data)
        elif "youtu" in name:
            YoutubeTranscriptReader = download_loader("YoutubeTranscriptReader")
            loader = YoutubeTranscriptReader()
            documents = loader.load_data(ytlinks=[name])
        elif "http" in name:
            AsyncWebPageReader = download_loader("AsyncWebPageReader")
            loader = AsyncWebPageReader()
            documents = loader.load_data(urls=[name])
        # elif ext in [".png", ".jpeg", ".jpg"]:
        #     ImageCaptionReader = download_loader("ImageCaptionReader")
        #     loader = ImageCaptionReader()
        #     documents = loader.load_data(file=data)
        else:
            try:
                MarkdownReader = download_loader("MarkdownReader")
                loader = MarkdownReader()
                documents = loader.load_data(file=data)
            except:
                st.error(f"éå¯¾å¿œã®ãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼ã§ã™ã€‚ï¼š{name}")
                st.stop()

        # dimensions of text-ada-embedding-002
        d = 1536
        # ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦
        faiss_index = faiss.IndexFlatIP(d)
        vector_store = FaissVectorStore(faiss_index=faiss_index)
        storage_context = StorageContext.from_defaults(vector_store=vector_store)

        index = GPTVectorStoreIndex.from_documents(
            documents, faiss_index=faiss_index, service_context=service_context
        )
        # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®ä¿å­˜
        # index.storage_context.persist()

    query_engine = index.as_query_engine(
        similarity_top_k=3,
    )

    return query_engine


def chat(text, settings, max_tokens, model):

    messages = [
        {"role": "system", "content": settings},
        {"role": "user", "content": text},
    ]

    try_count = 3
    for try_time in range(try_count):
        try:
            resp = openai.ChatCompletion.create(
                model=model,
                messages=messages,
                max_tokens=max_tokens,
                stream=True,
                timeout=120,
                request_timeout=120,
            )
            return resp

        except openai.error.APIError:
            time.sleep(1)
        except openai.error.InvalidRequestError:
            pass
        except (
            openai.error.RateLimitError,
            openai.error.RateLimitError,
            openai.error.openai.error.APIConnectionError,
        ):
            time.sleep(10)


def main():
    if "alltext" not in st.session_state:
        st.session_state["alltext"] = []

    st.write("# ğŸ“šLearnMateAI ")
    st.write("---")
    status_place = st.container()

    with st.sidebar:
        with st.expander("ğŸ“šLearnMateAIã¨ã¯"):
            st.write(
                """
æŒ‡å®šã•ã‚ŒãŸãƒ†ãƒ¼ãƒã¨å¯¾è±¡è€…ã®ãƒ¬ãƒ™ãƒ«ã«æ²¿ã£ãŸè³‡æ–™ã‚’ç”Ÿæˆã™ã‚‹AIã§ã™ã€‚  

ç”Ÿæˆæ–‡å­—æ•°ã‚’300æ–‡å­—ä»¥å†…ã«æŒ‡å®šã™ã‚‹ã¨æ¦‚è¦èª¬æ˜è³‡æ–™ã‚’ç”Ÿæˆã—ã€ãã‚Œä»¥ä¸Šã‚ã‚‹ã„ã¯0ï¼ˆæŒ‡å®šãªã—ï¼‰ã¨ã™ã‚‹ã¨è©³ç´°ãªè³‡æ–™ã‚’ç”Ÿæˆã—ã¾ã™ã€‚
â€»ç ”ä¿®ã‚„å°å…¥è³‡æ–™ã¨ã—ã¦ä½¿ãˆã‚‹ã‚ˆã†ã«ã€ç†è§£åº¦ã‚’ç¢ºèªã™ã‚‹ãŸã‚ã®ã‚¯ã‚¤ã‚ºä»˜ã

ç‹¬è‡ªãƒ‡ãƒ¼ã‚¿ï¼ˆtxt,docx,pdf,pptx,mp3,ã‚¦ã‚§ãƒ–ãƒšãƒ¼ã‚¸,Youtubeï¼‰ã‚’ã‚‚ã¨ã«ã‚¬ã‚¤ãƒ‰ã‚’ä½œæˆã™ã‚‹ã“ã¨ã‚‚ã§ãã¾ã™ã€‚

> æ´»ç”¨ä¾‹
> - ç‰¹å®šã®ãƒ†ãƒ¼ãƒã«æ²¿ã£ãŸç ”ä¿®è³‡æ–™ä½œæˆ
> - è‡ªå·±å­¦ç¿’ç”¨ã®è³‡æ–™ä½œæˆ
> - ç¤¾å†…è³‡æ–™ã‚’ã‚‚ã¨ã«æ–°è¦å‚å…¥è€…ã®å—å…¥è³‡æ–™ä½œæˆã€ãƒãƒ‹ãƒ¥ã‚¢ãƒ«ã®ä½œæˆ  
> - ä¼šè­°ã®éŒ²éŸ³ãƒ‡ãƒ¼ã‚¿ã‚’å…ƒã«è­°äº‹éŒ²ã‚’ä½œæˆ  
> - ã‚¦ã‚§ãƒ–ãƒšãƒ¼ã‚¸ã®è¦ç´„  
> - Youtubeå‹•ç”»ã®è¦ç´„ï¼ˆå­—å¹•ä»˜ãå‹•ç”»ã®ã¿ï¼‰
"""
            )
            st.caption("*powered by GPT-3,GPT-4*")

        with st.form("settings"):
            model = st.selectbox("ãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠ", ["gpt-3.5-turbo", "gpt-4"])
            inputtext = st.text_input("ãƒ†ãƒ¼ãƒ", help="å¿…é ˆ")
            supplement = st.text_area("è£œè¶³", help="ä»»æ„")
            level = st.selectbox("ãƒ¬ãƒ™ãƒ«ã‚’é¸æŠ", ["åˆå¿ƒè€…", "ä¸­ä¸Šç´šè€…"])
            input_gen_length = st.number_input(
                "ç”Ÿæˆæ–‡å­—æ•°ã‚’å…¥åŠ›", min_value=0, step=100, value=1000, help="0ã«è¨­å®šã™ã‚‹ã¨æŒ‡å®šãªã—ã¨ãªã‚Šã¾ã™ã€‚"
            )
            with st.expander("ç‹¬è‡ªãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ã™ã‚‹"):
                orginal_file = st.file_uploader(
                    "ãƒ•ã‚¡ã‚¤ãƒ«", type=["txt", "md", "docx", "pdf", "pptx", "mp3", "mp4"]
                )
                if not orginal_file:
                    orginal_file = st.text_input(
                        "URL (WebSite,Youtube ect)", help="Youtubeã¯å­—å¹•ä»˜å‹•ç”»ã®ã¿ã€‚"
                    )

            reading = True

            submit = st.form_submit_button("ç”Ÿæˆé–‹å§‹")

    if submit:
        st.session_state["alltext"] = []
        st.write(f"## ãƒ†ãƒ¼ãƒï¼š{inputtext}")
        if orginal_file:
            if type(orginal_file) == str:
                st.write(f"OriginalSource : {orginal_file}")
            else:
                st.write(f"OriginalSource : {orginal_file.name}")

        st.session_state["alltext"] = []
        llm = ChatOpenAI(
            temperature=0,
            model_name=model,
            streaming=True,
            max_tokens=2000,
            callback_manager=BaseCallbackManager(
                [WrapStreamlitCallbackHandler()],
            ),
        )

        if orginal_file:
            if type(orginal_file) == str:
                query_engine = make_query_engine(
                    orginal_file,
                    llm=llm,
                    reading=False,
                    name=orginal_file,
                )
            else:
                with tempfile.NamedTemporaryFile(delete=False) as tmp_file:
                    fp = Path(tmp_file.name)
                    fp.write_bytes(orginal_file.getvalue())
                    query_engine = make_query_engine(
                        tmp_file.name,
                        llm=llm,
                        reading=False,
                        name=orginal_file.name,
                    )

        if input_gen_length <= 300:
            gen_rule = f"æ¦‚è¦ã‚’æŠŠæ¡ã§ãã‚‹è³‡æ–™ã‚’{input_gen_length}æ–‡å­—ä»¥å†…ã§ä½œæˆã—ã¦ãã ã•ã„"
        else:
            gen_rule = f"{level}ãŒåŠ¹ç‡ã‚ˆãèƒ½åŠ›ã‚’é«˜ã‚ã‚‰ã‚Œã‚‹è³‡æ–™ã‚’{input_gen_length}æ–‡å­—ä»¥å†…ã§ä½œæˆã—ã¦ãã ã•ã„"

        base_instructions = f"""
ã‚ãªãŸã¯{inputtext}ã®å°‚é–€å®¶ã§ã™ã€‚
{inputtext}ã«ã¤ã„ã¦ã€{gen_rule}ã€‚
ä½œæˆã«å½“ãŸã£ã¦ã¯ä»¥ä¸‹ã«å³å¯†ã«å¾“ã£ã¦ãã ã•ã„ã€‚
- æŒ‡ç¤ºã®æœ€å¾Œã«[ç¶šãã‚’å‡ºåŠ›]ã¨é€ã‚‰ã‚ŒãŸå ´åˆã¯ã€[ç¶šãã‚’å‡ºåŠ›]ã®å‰ã®æ–‡ç« ã®ç¶šãã‚’å‡ºåŠ›ã™ã‚‹ã€‚
- step by stepã§è¤‡æ•°å›æ¤œè¨ã‚’è¡Œã„ã€ãã®ä¸­ã§ä¸€ç•ªå„ªã‚Œã¦ã„ã‚‹ã¨æ€ã†çµæœã‚’å‡ºåŠ›ã™ã‚‹ã€‚
- ã‚µãƒ³ãƒ—ãƒ«ã§ã¯ãªããã®ã¾ã¾åˆ©ç”¨ã§ãã‚‹ä½“è£ã¨ã—ã€å†…å®¹ã¯è©³ç´°ã«è¨˜è¼‰ã™ã‚‹ã€‚
- å‡ºåŠ›ã¯Markdownã¨ã™ã‚‹ã€‚
- ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ã‚’åˆ©ç”¨ã—ã¦ã‚µãƒ³ãƒ—ãƒ«ã‚³ãƒ¼ãƒ‰ã‚’å‡ºåŠ›ã™ã‚‹ã€‚
- å„èª¬æ˜ã®å¾Œã¯èª¬æ˜ã—ãŸå†…å®¹ã®å®Ÿä¾‹ã‚’å…¥ã‚Œã‚‹ã€‚
- ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®ä¸­ç›¤ã§ã¯ãƒ–ãƒ¬ã‚¤ã‚¯ã‚¿ã‚¤ãƒ ã¨ã—ã¦è±†çŸ¥è­˜ã‚’ç¹”ã‚Šäº¤ãœã‚‹ã€‚
- ç”»åƒã‚„çµµæ–‡å­—ã€ã‚¢ã‚¤ã‚³ãƒ³ç­‰ã‚’ä½¿ç”¨ã—è¦–è¦šçš„ã«èˆˆå‘³ã‚’å¼•ãå·¥å¤«ã‚’è¡Œã†ã€‚
- å›³ã‚„ã‚°ãƒ©ãƒ•ã‚’è¡¨ç¤ºã™ã‚‹éš›ã¯marmaid.jså½¢å¼ã¨ã™ã‚‹ã€‚
- å‡ºå…¸ã‚’æ˜è¨˜ã™ã‚‹ã€‚
- ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã”ã¨ã«ç†è§£åº¦ã‚’ç¢ºèªã™ã‚‹ç°¡å˜ãªã‚¯ã‚¤ã‚ºã‚’ä½œæˆã™ã‚‹ã€‚
- ç”Ÿæˆç‰©ä»¥å¤–ã¯å‡ºåŠ›ã—ãªã„ï¼ˆä¾‹ãˆã°ç”Ÿæˆç‰©ã«å¯¾ã™ã‚‹ã‚³ãƒ¡ãƒ³ãƒˆã‚„èª¬æ˜ãªã©ï¼‰
{supplement}
"""
        if orginal_file:
            instructions = f"ã€€ãƒ«ãƒ¼ãƒ«:{input_gen_length}æ–‡å­—ä»¥å†…ã§å‡ºåŠ›ã€‚Markdownã§å‡ºåŠ›ã€‚æ—¥æœ¬èªã§å‡ºåŠ›ã€‚{level}å‘ã‘ã€‚{supplement}"
        elif level == "åˆå¿ƒè€…":
            instructions = f"""
{base_instructions}
- ä»Šå¾Œã®å­¦ç¿’ãƒ­ãƒ¼ãƒ‰ãƒãƒƒãƒ—ã‚’ä½œæˆã™ã‚‹ã€‚
- æ¬¡ã®ãƒ¬ãƒ™ãƒ«ã«é€²ã‚€ãŸã‚ã®æ•™æã‚’ç´¹ä»‹ã™ã‚‹ã€‚
            """
        elif level == "ä¸­ä¸Šç´šè€…":
            instructions = f"""
{base_instructions}
- åŸºæœ¬çš„ã¯éƒ¨åˆ†ã®èª¬æ˜ã¯çœç•¥ã—ã€ãƒ‹ãƒƒãƒãªå†…å®¹ã‚„é«˜åº¦ãªæŠ€è¡“ã‚’ä¸­å¿ƒã«æ§‹æˆã™ã‚‹ã€‚
- é–¢é€£ã™ã‚‹åˆ¥ã®åˆ†é‡ã®ç ”ç©¶å†…å®¹ãªã©ã‚‚ç´¹ä»‹ã™ã‚‹ã€‚
- ã‚ˆã‚Šæ·±ãå­¦ç¿’ã™ã‚‹ãŸã‚ã®è³‡æ–™ãªã©ã‚’ç´¹ä»‹ã™ã‚‹ã€‚
            """

        if inputtext:
            st.session_state["alltext"].append(inputtext)
            text = ""

            with st.spinner(text="ç”Ÿæˆä¸­..."):
                new_place = st.empty()
                finish_reason = "init"
                completion = ""
                while True:
                    if finish_reason == "init":
                        message = "".join(st.session_state["alltext"])
                    elif finish_reason == "stop":
                        break
                    elif finish_reason == "length":
                        message = "".join(st.session_state["alltext"]) + "[ç¶šãã‚’å‡ºåŠ›]"
                    else:
                        st.error(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚finish_reason={finish_reason}")
                        st.stop

                    message = message[0:3500]

                    response = ""
                    if orginal_file:
                        response = query_engine.query(message + instructions)
                        break
                    else:
                        completion = chat(
                            text=message,
                            settings=instructions,
                            max_tokens=3500,
                            model=model,
                        )
                        for chunk in completion:
                            finish_reason = chunk["choices"][0].get("finish_reason", "")
                            next = chunk["choices"][0]["delta"].get("content", "")
                            text += next
                            text = text.replace("[æŒ‡ç¤ºï¼šç¶šãã‚’å‡ºåŠ›]", "")
                            new_place.write(text)

                    st.session_state["alltext"].append(text)

            t_delta = datetime.timedelta(hours=9)
            JST = datetime.timezone(t_delta, "JST")
            now = datetime.datetime.now(JST)

            with status_place:
                st.write("### ğŸ‰ç”Ÿæˆå®Œäº†ï¼\n---")
                st.download_button(
                    "ãƒ†ã‚­ã‚¹ãƒˆã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                    file_name=f"LearnMateAI_{now.strftime('%Y%m%d%H%M%S')}.md",
                    data=response.response
                    if response
                    else "\n".join(st.session_state["alltext"]),
                    mime="text/plain",
                )


if __name__ == "__main__":
    st.set_page_config(page_title="LearnMateAI", page_icon="ğŸ“š", layout="wide")

    hide_streamlit_style = """
                <style>
                #MainMenu {visibility: hidden;}
                footer {visibility: hidden;}
                </style>
                """
    st.markdown(hide_streamlit_style, unsafe_allow_html=True)

    openai.api_key = st.secrets["OPEN_AI_KEY"]
    os.environ["OPENAI_API_KEY"] = st.secrets["OPEN_AI_KEY"]

    main()
