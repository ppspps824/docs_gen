import datetime
import os
import tempfile
import time
from pathlib import Path
from typing import Any, Dict, List

import faiss
import openai
import requests
import streamlit as st
from langchain.agents import AgentType, initialize_agent, load_tools
from langchain.callbacks.base import BaseCallbackManager
from langchain.callbacks.streamlit import StreamlitCallbackHandler
from langchain.chat_models import ChatOpenAI
from langchain.prompts import (
    ChatPromptTemplate,
    HumanMessagePromptTemplate,
    SystemMessagePromptTemplate,
)
from llama_index import (
    GPTVectorStoreIndex,
    PromptHelper,
    ServiceContext,
    StorageContext,
    download_loader,
    load_index_from_storage,
)
from llama_index.llm_predictor.chatgpt import ChatGPTLLMPredictor
from llama_index.vector_stores.faiss import FaissVectorStore
from streamlit_lottie import st_lottie, st_lottie_spinner


# promptsã®å‡ºåŠ›ã‚’è¡Œã‚ãªã„ãŸã‚ãƒ©ãƒƒãƒ—
class WrapStreamlitCallbackHandler(StreamlitCallbackHandler):
    def on_llm_start(
        self, serialized: Dict[str, Any], prompts: List[str], **kwargs: Any
    ) -> None:
        pass


def load_lottieurl(url: str):
    r = requests.get(url)
    if r.status_code != 200:
        return None
    return r.json()


def make_query_engine(data, llm, reading, name):

    check_name = name.lower()
    if reading:
        # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®èª­ã¿è¾¼ã¿
        storage_context = StorageContext.from_defaults(persist_dir="./storage")
        index = load_index_from_storage(storage_context)
    else:
        prompt_helper = PromptHelper(
            max_input_size=4096, num_output=2048, max_chunk_overlap=20
        )
        llm_predictor = ChatGPTLLMPredictor(llm=llm)
        service_context = ServiceContext.from_defaults(
            llm_predictor=llm_predictor,
            prompt_helper=prompt_helper,
            chunk_size_limit=512,
        )
        if ".pdf" in check_name:
            PDFReader = download_loader("PDFReader")
            loader = PDFReader()
            documents = loader.load_data(file=data)
        elif any([".txt" in check_name, ".md" in name]):
            MarkdownReader = download_loader("MarkdownReader")
            loader = MarkdownReader()
            documents = loader.load_data(file=data)
        elif ".pptx" in check_name:
            PptxReader = download_loader("PptxReader")
            loader = PptxReader()
            documents = loader.load_data(file=data)
        elif ".docx" in check_name:
            DocxReader = download_loader("DocxReader")
            loader = DocxReader()
            documents = loader.load_data(file=data)
        elif any([".mp3" in check_name, ".mp4" in check_name]):
            AudioTranscriber = download_loader("AudioTranscriber")
            loader = AudioTranscriber()
            documents = loader.load_data(file=data)
        elif "youtu" in check_name:
            YoutubeTranscriptReader = download_loader("YoutubeTranscriptReader")
            loader = YoutubeTranscriptReader()
            documents = loader.load_data(ytlinks=[name])
        elif "http" in check_name:
            AsyncWebPageReader = download_loader("AsyncWebPageReader")
            loader = AsyncWebPageReader()
            documents = loader.load_data(urls=[name])
        # elif ext in [".png", ".jpeg", ".jpg"]:
        #     ImageCaptionReader = download_loader("ImageCaptionReader")
        #     loader = ImageCaptionReader()
        #     documents = loader.load_data(file=data)
        else:
            try:
                MarkdownReader = download_loader("MarkdownReader")
                loader = MarkdownReader()
                documents = loader.load_data(file=data)
            except:
                st.error(f"éå¯¾å¿œã®ãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼ã§ã™ã€‚ï¼š{name}")
                st.stop()

        # dimensions of text-ada-embedding-002
        d = 1536
        # ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦
        faiss_index = faiss.IndexFlatIP(d)
        vector_store = FaissVectorStore(faiss_index=faiss_index)
        storage_context = StorageContext.from_defaults(vector_store=vector_store)

        index = GPTVectorStoreIndex.from_documents(
            documents, faiss_index=faiss_index, service_context=service_context
        )
        # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®ä¿å­˜
        # index.storage_context.persist()

    query_engine = index.as_query_engine(
        similarity_top_k=3,
    )

    return query_engine


def chat(text, settings, max_tokens, model):
    # # ä½¿ç”¨ã™ã‚‹ãƒ„ãƒ¼ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰
    # tools = ["google-search", "python_repl"]
    # tools = load_tools(tools, llm=model)

    # system_template = settings
    # human_template = "è³ªå•è€…ï¼š{question}"
    # system_message_prompt = SystemMessagePromptTemplate.from_template(system_template)
    # human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)

    # chat_prompt = ChatPromptTemplate.from_messages(
    #     [system_message_prompt, human_message_prompt]
    # )
    # prompt_message_list = chat_prompt.format_prompt(
    #     language="æ—¥æœ¬èª", question=text
    # ).to_messages()
    # print(prompt_message_list)
    # try:
    #     agent = initialize_agent(
    #         tools=tools,
    #         llm=model,
    #         agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,
    #         verbose=True,
    #     )
    #     response = agent.run(prompt_message_list)

    # except Exception as e:
    #     response = str(e)
    #     if not response.startswith("Could not parse LLM output: `"):
    #         raise e
    #     response = response.removeprefix("Could not parse LLM output: `").removesuffix(
    #         "`"
    #     )

    # return response
    messages = [
        {"role": "system", "content": settings},
        {"role": "user", "content": text},
    ]

    try_count = 3
    for try_time in range(try_count):
        try:
            resp = openai.ChatCompletion.create(
                model=model,
                messages=messages,
                max_tokens=max_tokens,
                stream=True,
                timeout=120,
                request_timeout=120,
            )
            return resp

        except openai.error.APIError as e:
            print(e)
            print(f"retry:{try_time+1}/{try_count}")
            time.sleep(1)
        except openai.error.InvalidRequestError as e:
            print(e)
            print(f"retry:{try_time+1}/{try_count}")
            pass
        except (
            openai.error.RateLimitError,
            openai.error.openai.error.APIConnectionError,
        ) as e:
            print(e)
            print(f"retry:{try_time+1}/{try_count}")
            time.sleep(10)


def disable():
    st.session_state.disabled = True


def create_messages(
    input_gen_length=0, inputtext="", supplement="", level="", orginal_file=None
):
    if input_gen_length <= 300:
        gen_rule = f"æ¦‚è¦ã‚’æŠŠæ¡ã§ãã‚‹è³‡æ–™ã‚’{input_gen_length}æ–‡å­—ä»¥å†…ã§ä½œæˆã—ã¦ãã ã•ã„"
    else:
        gen_rule = f"è©³ç´°ã‚’ã¾ã¨ã‚ãŸè³‡æ–™ã‚’{input_gen_length}æ–‡å­—ä»¥å†…ã§ä½œæˆã—ã¦ãã ã•ã„"

    base_instructions = f"""
ã‚ãªãŸã¯{inputtext}ã®å°‚é–€å®¶ã§ã™ã€‚
{inputtext}ã«ã¤ã„ã¦ã€{gen_rule}ã€‚
ä½œæˆã«å½“ãŸã£ã¦ã¯ä»¥ä¸‹ã«å³å¯†ã«å¾“ã£ã¦ãã ã•ã„ã€‚
- æŒ‡ç¤ºã®æœ€å¾Œã«ç¶šãã‚’å‡ºåŠ›ã¨é€ã‚‰ã‚ŒãŸå ´åˆã¯ã€ç¶šãã‚’å‡ºåŠ›ã®å‰ã®æ–‡ç« ã®ç¶šãã‚’å‡ºåŠ›ã™ã‚‹ã€‚
- step by stepã§è¤‡æ•°å›æ¤œè¨ã‚’è¡Œã„ã€ãã®ä¸­ã§ä¸€ç•ªå„ªã‚Œã¦ã„ã‚‹ã¨æ€ã†çµæœã‚’å‡ºåŠ›ã™ã‚‹ã€‚
- å‡ºåŠ›ã¯Markdownã¨ã™ã‚‹ã€‚
- ç”Ÿæˆç‰©ä»¥å¤–ã¯å‡ºåŠ›ã—ãªã„ï¼ˆä¾‹ãˆã°ç”Ÿæˆç‰©ã«å¯¾ã™ã‚‹ã‚³ãƒ¡ãƒ³ãƒˆã‚„èª¬æ˜ãªã©ï¼‰
        {supplement}
        """
    traning_base = """
- ã‚µãƒ³ãƒ—ãƒ«ã§ã¯ãªããã®ã¾ã¾åˆ©ç”¨ã§ãã‚‹ä½“è£ã¨ã—ã€å†…å®¹ã¯è©³ç´°ã«è¨˜è¼‰ã™ã‚‹ã€‚
- ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ã‚’åˆ©ç”¨ã—ã¦ã‚µãƒ³ãƒ—ãƒ«ã‚³ãƒ¼ãƒ‰ã‚’å‡ºåŠ›ã™ã‚‹ã€‚
- å„èª¬æ˜ã®å¾Œã¯èª¬æ˜ã—ãŸå†…å®¹ã®å®Ÿä¾‹ã‚’å…¥ã‚Œã‚‹ã€‚
- ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®ä¸­ç›¤ã§ã¯ãƒ–ãƒ¬ã‚¤ã‚¯ã‚¿ã‚¤ãƒ ã¨ã—ã¦è±†çŸ¥è­˜ã‚’ç¹”ã‚Šäº¤ãœã‚‹ã€‚
- ç”»åƒã‚„çµµæ–‡å­—ã€ã‚¢ã‚¤ã‚³ãƒ³ç­‰ã‚’ä½¿ç”¨ã—è¦–è¦šçš„ã«èˆˆå‘³ã‚’å¼•ãå·¥å¤«ã‚’è¡Œã†ã€‚
- å›³ã‚„ã‚°ãƒ©ãƒ•ã‚’è¡¨ç¤ºã™ã‚‹éš›ã¯marmaid.jså½¢å¼ã¨ã™ã‚‹ã€‚
- å‡ºå…¸ã‚’æ˜è¨˜ã™ã‚‹ã€‚
- ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã”ã¨ã«ç†è§£åº¦ã‚’ç¢ºèªã™ã‚‹ç°¡å˜ãªã‚¯ã‚¤ã‚ºã‚’ä½œæˆã™ã‚‹ã€‚
                """
    if orginal_file:
        instructions = f"ã€€ãƒ«ãƒ¼ãƒ«:Markdownã§å‡ºåŠ›ã€‚æ—¥æœ¬èªã§å‡ºåŠ›ã€‚{supplement}"
    elif level == "å…¥é–€è³‡æ–™":
        instructions = f"""
{base_instructions}
{traning_base}
- ä»Šå¾Œã®å­¦ç¿’ãƒ­ãƒ¼ãƒ‰ãƒãƒƒãƒ—ã‚’ä½œæˆã™ã‚‹ã€‚
- æ¬¡ã®ãƒ¬ãƒ™ãƒ«ã«é€²ã‚€ãŸã‚ã®æ•™æã‚’ç´¹ä»‹ã™ã‚‹ã€‚
                    """
    elif level == "ä¸­ä¸Šç´šè€…å‘ã‘è³‡æ–™":
        instructions = f"""
{base_instructions}
{traning_base}
- åŸºæœ¬çš„ã¯éƒ¨åˆ†ã®èª¬æ˜ã¯çœç•¥ã—ã€ãƒ‹ãƒƒãƒãªå†…å®¹ã‚„é«˜åº¦ãªæŠ€è¡“ã‚’ä¸­å¿ƒã«æ§‹æˆã™ã‚‹ã€‚
- é–¢é€£ã™ã‚‹åˆ¥ã®åˆ†é‡ã®ç ”ç©¶å†…å®¹ãªã©ã‚‚ç´¹ä»‹ã™ã‚‹ã€‚
- ã‚ˆã‚Šæ·±ãå­¦ç¿’ã™ã‚‹ãŸã‚ã®è³‡æ–™ãªã©ã‚’ç´¹ä»‹ã™ã‚‹ã€‚
                    """
    elif level == "ãƒ•ãƒªãƒ¼ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ":
        instructions = base_instructions

    return instructions


def main():
    if "alltext" not in st.session_state:
        st.session_state.alltext = []
        st.session_state.savetext = []
        st.session_state.disabled = False
    col1, col2, _ = st.columns(3)
    with col2:
        st.markdown("#")
        st.markdown("#")
        st.markdown("# LearnMate.AI ")
    with col1:
        lottie_url = "https://assets9.lottiefiles.com/packages/lf20_glpbhbuh.json"
        lottie_json = load_lottieurl(lottie_url)
        st_lottie(lottie_json, height=200, loop=False)

    message_place = st.empty()

    with st.sidebar:
        tab1, tab2, tab3 = st.tabs(["About", "è³‡æ–™ä½œæˆ", "å¯¾è©±æ¤œç´¢"])
        with tab1:
            st.markdown("## ğŸ“šLearnMate.AIã¨ã¯")
            st.markdown(
                """
    æŒ‡å®šã•ã‚ŒãŸãƒ†ãƒ¼ãƒã«ã¤ã„ã¦ã€é¸æŠã—ãŸå½¢å¼ã®è³‡æ–™ã‚’ç”Ÿæˆã™ã‚‹AIã§ã™ã€‚  

    ç”Ÿæˆæ–‡å­—æ•°ã‚’300æ–‡å­—ä»¥å†…ã«æŒ‡å®šã™ã‚‹ã¨æ¦‚è¦èª¬æ˜è³‡æ–™ã‚’ç”Ÿæˆã—ã€ãã‚Œä»¥ä¸Šã‚ã‚‹ã„ã¯0ï¼ˆæŒ‡å®šãªã—ï¼‰ã¨ã™ã‚‹ã¨è©³ç´°ãªè³‡æ–™ã‚’ç”Ÿæˆã—ã¾ã™ã€‚
    â€»ç ”ä¿®ã‚„å°å…¥è³‡æ–™ã¨ã—ã¦ä½¿ãˆã‚‹ã‚ˆã†ã«ã€ç†è§£åº¦ã‚’ç¢ºèªã™ã‚‹ãŸã‚ã®ã‚¯ã‚¤ã‚ºä»˜ã

    ç‹¬è‡ªãƒ‡ãƒ¼ã‚¿ï¼ˆtxt,docx,pdf,pptx,mp3,ã‚¦ã‚§ãƒ–ãƒšãƒ¼ã‚¸,Youtubeï¼‰ã‚’ã‚‚ã¨ã«ã‚¬ã‚¤ãƒ‰ã‚’ä½œæˆã™ã‚‹ã“ã¨ã‚‚ã§ãã¾ã™ã€‚

    > æ´»ç”¨ä¾‹
    > - ç‰¹å®šã®ãƒ†ãƒ¼ãƒã«æ²¿ã£ãŸç ”ä¿®è³‡æ–™ä½œæˆ
    > - è‡ªå·±å­¦ç¿’ç”¨ã®è³‡æ–™ä½œæˆ
    > - ç¤¾å†…è³‡æ–™ã‚’ã‚‚ã¨ã«æ–°è¦å‚å…¥è€…ã®å—å…¥è³‡æ–™ä½œæˆã€ãƒãƒ‹ãƒ¥ã‚¢ãƒ«ã®ä½œæˆ  
    > - ä¼šè­°ã®éŒ²éŸ³ãƒ‡ãƒ¼ã‚¿ã‚’å…ƒã«è­°äº‹éŒ²ã‚’ä½œæˆ  
    > - ã‚¦ã‚§ãƒ–ãƒšãƒ¼ã‚¸ã®è¦ç´„  
    > - Youtubeå‹•ç”»ã®è¦ç´„ï¼ˆå­—å¹•ä»˜ãå‹•ç”»ã®ã¿ï¼‰
    """
            )
            st.caption("*powered by GPT-3,GPT-4*")
        with tab2:
            with st.form("tab2"):
                model = st.selectbox("ãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠ", ["gpt-3.5-turbo", "gpt-4"])
                inputtext = st.text_input("ãƒ†ãƒ¼ãƒ", help="å¿…é ˆ")
                supplement = st.text_area("è£œè¶³", help="ä»»æ„")
                level = st.selectbox("å½¢å¼ã‚’é¸æŠ", ["ãƒ•ãƒªãƒ¼ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ", "å…¥é–€è³‡æ–™", "ä¸­ä¸Šç´šè€…å‘ã‘è³‡æ–™"])
                input_gen_length = st.number_input(
                    "ç”Ÿæˆæ–‡å­—æ•°ã‚’å…¥åŠ›",
                    min_value=0,
                    step=100,
                    value=1000,
                    help="0ã«è¨­å®šã™ã‚‹ã¨æŒ‡å®šãªã—ã¨ãªã‚Šã¾ã™ã€‚",
                )

                reading = True

                submit = st.form_submit_button(
                    "ç”Ÿæˆé–‹å§‹",  # on_click=disable, disabled=st.session_state.disabled
                )

        with tab3:
            with st.form("tab3"):
                model = st.selectbox("ãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠ", ["gpt-3.5-turbo", "gpt-4"])
                inputtext = st.text_area("å…¥åŠ›")
                orginal_file = st.file_uploader(
                    "ãƒ•ã‚¡ã‚¤ãƒ«", type=["txt", "md", "docx", "pdf", "pptx", "mp3", "mp4"]
                )
                if not orginal_file:
                    orginal_file = st.text_input(
                        "URL (WebSite,Youtube...)", help="Youtubeã¯å­—å¹•ä»˜å‹•ç”»ã®ã¿ã€‚"
                    )

                reading = True

                submit = st.form_submit_button(
                    "ç”Ÿæˆé–‹å§‹",  # on_click=disable, disabled=st.session_state.disabled
                )

    if not submit:
        # ç´¹ä»‹å‹•ç”»ã‚’æµã™
        pass

    for no, info in enumerate(st.session_state.savetext):
        t_delta = datetime.timedelta(hours=9)
        JST = datetime.timezone(t_delta, "JST")
        now = datetime.datetime.now(JST)
        with st.expander(f'{info["theme"]}'):
            if info["origine_name"]:
                data = (
                    f"## {info['theme']}"
                    + "\n"
                    + f"OriginalSource : {info['origine_name']}"
                    + "\n"
                    + info["value"]
                )
            else:
                data = info["theme"] + "\n" + info["value"]
            st.download_button(
                "ãƒ†ã‚­ã‚¹ãƒˆã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                file_name=f"{info['theme']}_{now.strftime('%Y%m%d%H%M%S')}.md",
                data=data,
                mime="text/plain",
                key=f"old_text{no}",
            )
            st.markdown(f"## {info['theme']}")
            if info["origine_name"]:
                st.markdown(f"OriginalSource : {info['origine_name']}")
            st.markdown(info["value"])

    if submit:
        instructions = create_messages(
            input_gen_length, inputtext, supplement, level, orginal_file
        )
        if inputtext:
            st.session_state.alltext = []
            st.markdown("---")
            st.markdown(f"## {inputtext}")

            if orginal_file:
                if type(orginal_file) == str:
                    st.markdown(f"OriginalSource : {orginal_file}")
                else:
                    st.markdown(f"OriginalSource : {orginal_file.name}")
            status_place = st.container()
            lottie_url = "https://assets4.lottiefiles.com/packages/lf20_45movo.json"
            spinner_lottie_json = load_lottieurl(lottie_url)
            with st_lottie_spinner(spinner_lottie_json, height=200):
                st.markdown("---")
                st.session_state.alltext = []
                llm = ChatOpenAI(
                    temperature=0,
                    model_name=model,
                    streaming=True,
                    max_tokens=2000,
                    callback_manager=BaseCallbackManager(
                        [WrapStreamlitCallbackHandler()],
                    ),
                )

                if orginal_file:
                    if type(orginal_file) == str:
                        query_engine = make_query_engine(
                            orginal_file,
                            llm=llm,
                            reading=False,
                            name=orginal_file,
                        )
                    else:
                        with tempfile.NamedTemporaryFile(delete=False) as tmp_file:
                            fp = Path(tmp_file.name)
                            fp.write_bytes(orginal_file.getvalue())
                            query_engine = make_query_engine(
                                fp,
                                llm=llm,
                                reading=False,
                                name=orginal_file.name,
                            )

                st.session_state.alltext.append(inputtext)
                text = ""

                new_place = st.empty()
                finish_reason = "init"
                completion = ""
                while True:
                    if finish_reason == "init":
                        message = "".join(st.session_state.alltext)
                    elif finish_reason == "stop":
                        break
                    elif finish_reason == "length":
                        message = "".join(st.session_state.alltext) + "ç¶šãã‚’å‡ºåŠ›"
                    else:
                        st.error(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚finish_reason={finish_reason}")
                        st.stop

                    message = message[0:3500]

                    response = ""
                    if orginal_file:
                        response = query_engine.query(message + instructions)
                        break
                    else:
                        completion = chat(
                            text=message,
                            settings=instructions,
                            max_tokens=3500,
                            model=model,
                        )
                        for chunk in completion:
                            finish_reason = chunk["choices"][0].get("finish_reason", "")
                            next = chunk["choices"][0]["delta"].get("content", "")
                            text += next
                            text = text.replace("ç¶šãã‚’å‡ºåŠ›", "")
                            new_place.write(text)

                    st.session_state.alltext.append(text)
                    origine_name = ""
                    if orginal_file:
                        if type(orginal_file) == str:
                            origine_name = orginal_file
                        else:
                            origine_name = orginal_file.nam

                    st.session_state.savetext.append(
                        {
                            "theme": inputtext,
                            "value": text,
                            "origine_name": origine_name,
                        }
                    )
                    st.session_state.disabled = False

                t_delta = datetime.timedelta(hours=9)
                JST = datetime.timezone(t_delta, "JST")
                now = datetime.datetime.now(JST)

                with status_place:
                    lottie_url = "https://assets2.lottiefiles.com/datafiles/8UjWgBkqvEF5jNoFcXV4sdJ6PXpS6DwF7cK4tzpi/Check Mark Success/Check Mark Success Data.json"
                    lottie_json = load_lottieurl(lottie_url)
                    st_lottie(lottie_json, height=100, loop=False)
                    st.download_button(
                        "ãƒ†ã‚­ã‚¹ãƒˆã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                        file_name=f"{inputtext}_{now.strftime('%Y%m%d%H%M%S')}.md",
                        data=response.response
                        if response
                        else "\n".join(st.session_state.alltext),
                        mime="text/plain",
                        key="current_text",
                    )
        else:
            message_place.error("ãƒ†ãƒ¼ãƒã‚’å…¥åŠ›ã—ã¦ãã ã•ã„", icon="ğŸ¥º")


if __name__ == "__main__":
    st.set_page_config(page_title="LearnMate.AI", page_icon="ğŸ“š", layout="wide")

    hide_streamlit_style = """
                <style>
               .block-container {
                    padding-top: 2rem;
                }
                #MainMenu {visibility: hidden;}
                footer {visibility: hidden;}
                </style>
                """
    st.markdown(hide_streamlit_style, unsafe_allow_html=True)

    os.environ["OPENAI_API_KEY"] = st.secrets["OPEN_AI_KEY"]
    os.environ["GOOGLE_API_KEY"] = st.secrets["GOOGLE_API_KEY"]
    os.environ["GOOGLE_CSE_ID"] = st.secrets["GOOGLE_CSE_ID"]

    main()
